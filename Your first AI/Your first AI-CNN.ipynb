{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hello Team, I think this is your first encounter with neural networks. This mini-project is to help you understand the various steps of learning with a neural network. This time, together you'll create a simple feed-forward neural net. Complexity of the neural nets that you'll create will keep increasing with time.\n",
    "\n",
    "#### The learning problem: We'll try to create an AI that can recognize handwritten digits in the famous MNIST database (the same one 3Blue1Brown's video series on neural networks is based on, if you haven't watched at least the first two videos in the series, I can guarantee you that you won't find a more clear/visual explanation on the web).\n",
    "\n",
    "#### How it's going to work: Below I have laid out the different steps in the process. Every member's task is to write the part of the code that he/she has been assigned to. If your understanding of how an ANN works is clear, hopefully all your contributions will wake up our AI (even if you don't communicate with each other!). \n",
    "\n",
    "#### We'll be using Keras to implement the neural network as I've said before. Steps are of course sequential. Good luck!\n",
    "\n",
    "# ref: https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the dataset \n",
    "import numpy as np\n",
    "from keras.datasets import mnist# <--- My contribution to our little AI\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 1: Create the data pipeline to feed the network (To be done by member 1)\n",
    "\"\"\"\n",
    "You have an image (or loads of them) which will give you a numeric feature vector that \n",
    "can be fed to the input layer of the neural net. But is that all the network is hungry for? No.\n",
    "It also requires a label for the image, in this case 0 or 1 or ... or 9. But the output layer of a \n",
    "neural net is often a probability distribution (meaning the sum of all the node-values or the \n",
    "activations of the output layer is 1) and the number of nodes in the output layer = number of \n",
    "different possible labels or class which for this case is 10. This means that you can interpret the \n",
    "activation of the j-th node in the output layer as the probability that the input belongs to the \n",
    "j-th class or has the j-th label. If you think about the cost function, you'll understand that we \n",
    "should convert our rudimentary labels into probability vectors too. So an image depicting 2 should \n",
    "have the label (0,0,1,0,...,0).\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Your mission should you choose to accept it, is to:\n",
    "1. Create a Python object called digits having two attributes train, test\n",
    "2. Make sure digit.train and digit.test are objects of the same type having two \n",
    "attributes features(=array of all the feature vectors) and labels(=array of all the label vectors).\n",
    "Every element of features is a numeric array representing an image \n",
    "(might be an array of greyscale intensity, might be something else).\n",
    "\"\"\"\n",
    "class Dataset():\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "class Data():\n",
    "    def __init__(self,features,labels):\n",
    "        self.features = (features.astype('float32')/ 255.0).reshape(features.shape[0], 28, 28, 1)\n",
    "        new_labels=np.zeros([labels.shape[0],10])\n",
    "        #trainY = to_categorical(trainY)\n",
    "        #testY = to_categorical(testY)\n",
    "        for i,label in enumerate(labels):\n",
    "            new_labels[i,label]=1\n",
    "        self.labels= new_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train=Data(trainX,trainy)\n",
    "test=Data(testX,testy)\n",
    "digits=Dataset(train,test)\n",
    "# to import train features: digits.train.features\n",
    "# to import train features: digits.train.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 16s 293us/step - loss: 0.3388 - accuracy: 0.8966 - val_loss: 0.1465 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 235us/step - loss: 0.1535 - accuracy: 0.9551 - val_loss: 0.0996 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 258us/step - loss: 0.1082 - accuracy: 0.9683 - val_loss: 0.0844 - val_accuracy: 0.9782\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 243us/step - loss: 0.0845 - accuracy: 0.9753 - val_loss: 0.0670 - val_accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 16s 287us/step - loss: 0.0683 - accuracy: 0.9796 - val_loss: 0.0648 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 20s 364us/step - loss: 0.0579 - accuracy: 0.9829 - val_loss: 0.0664 - val_accuracy: 0.9827\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 24s 445us/step - loss: 0.0491 - accuracy: 0.9857 - val_loss: 0.0642 - val_accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 23s 420us/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 0.0553 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 20s 364us/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.0600 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 20s 372us/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.0496 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Activation, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "# Step - 2: Design the network (To be done by member 2)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Now train the data on the training Data Set and evlaute on test Data set\n",
    "learning_history=model.fit(digits.train.features,train.labels,batch_size=200,epochs=10,shuffle=True,validation_split=.1)\n",
    "\n",
    "# Saving the model\n",
    "#model.save('knowledge_CNN.h5')\n",
    "\n",
    "# If one wants to delete the current model in memory\n",
    "#del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving the model\n",
    "model.save('knowledge_CNN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 107us/step\n",
      "60000/60000 [==============================] - 7s 118us/step\n",
      "Train score:0.0281  Test Score: 0.0475 \n",
      "Train Accuracy: 99.26 Test Accuracy: 98.44\n"
     ]
    }
   ],
   "source": [
    "# Step - 3: Save/Load and Test our AI (To be done by member 3)\n",
    "# Loading the model\n",
    "from keras.models import load_model\n",
    "our_1st_ai=load_model('knowledge_CNN.h5')\n",
    "\n",
    "\"\"\"\n",
    "Last but not the least:\n",
    "1. Save our model as knowledge.h5 file in the same folder as this notebook for future use.\n",
    "2. Load the neural network saved in knowledge.h5 into an object named our_1st_ai.\n",
    "3. Output the accuracy score of our_1st_ai on the training and test samples separately.\n",
    "4. Plot the loss function and model accuracy as a function of epochs using learning_history. \n",
    "\"\"\"\n",
    "\n",
    "score_test,acc_test=model.evaluate(digits.test.features,digits.test.labels,batch_size=100)\n",
    "score_train,acc_train=model.evaluate(digits.train.features,digits.train.labels,batch_size=100)\n",
    "print('Train score:%.4f '%score_train,'Test Score: %.4f '%score_test)\n",
    "print('Train Accuracy: %.2f'%(acc_train*100),'Test Accuracy: %.2f'%(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.axhline(1,linestyle='dashed')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation','loss'], loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f639841d2e8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f639841d630>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f639841d978>,\n",
       "  <matplotlib.lines.Line2D at 0x7f639841dcc0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f6398410eb8>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f639841dda0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f63983aa390>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(model.history.history['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srashti/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for a an image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 1 channel\n",
    "    img = img.reshape( 1,28, 28,1)\n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    # load the image\n",
    "    img = load_image('sample_image.png')\n",
    "    # load model\n",
    "    model = load_model('knowledge_CNN.h5')\n",
    "    # predict the class\n",
    "    digit = model.predict_classes(img)\n",
    "    print(digit[0])\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
