{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Your first AI-CNN2.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22pLruQJP7YP",
        "colab_type": "text"
      },
      "source": [
        "#### Hello Team, I think this is your first encounter with neural networks. This mini-project is to help you understand the various steps of learning with a neural network. This time, together you'll create a simple feed-forward neural net. Complexity of the neural nets that you'll create will keep increasing with time.\n",
        "\n",
        "#### The learning problem: We'll try to create an AI that can recognize handwritten digits in the famous MNIST database (the same one 3Blue1Brown's video series on neural networks is based on, if you haven't watched at least the first two videos in the series, I can guarantee you that you won't find a more clear/visual explanation on the web).\n",
        "\n",
        "#### How it's going to work: Below I have laid out the different steps in the process. Every member's task is to write the part of the code that he/she has been assigned to. If your understanding of how an ANN works is clear, hopefully all your contributions will wake up our AI (even if you don't communicate with each other!). \n",
        "\n",
        "#### We'll be using Keras to implement the neural network as I've said before. Steps are of course sequential. Good luck!\n",
        "\n",
        "# ref: https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVk-SkGfP7YS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the dataset\n",
        "import tensorflow as tf \n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.datasets import mnist# <--- My contribution to our little AI\n",
        "import time\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SO23K8oRpjI",
        "outputId": "1b10c753-b184-494b-a1ff-e4ad9e55a1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.98.119.210:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.98.119.210:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.119.210:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.119.210:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK4eaJ04P7Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step - 1: Create the data pipeline to feed the network (To be done by member 1)\n",
        "\"\"\"\n",
        "You have an image (or loads of them) which will give you a numeric feature vector that \n",
        "can be fed to the input layer of the neural net. But is that all the network is hungry for? No.\n",
        "It also requires a label for the image, in this case 0 or 1 or ... or 9. But the output layer of a \n",
        "neural net is often a probability distribution (meaning the sum of all the node-values or the \n",
        "activations of the output layer is 1) and the number of nodes in the output layer = number of \n",
        "different possible labels or class which for this case is 10. This means that you can interpret the \n",
        "activation of the j-th node in the output layer as the probability that the input belongs to the \n",
        "j-th class or has the j-th label. If you think about the cost function, you'll understand that we \n",
        "should convert our rudimentary labels into probability vectors too. So an image depicting 2 should \n",
        "have the label (0,0,1,0,...,0).\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Your mission should you choose to accept it, is to:\n",
        "1. Create a Python object called digits having two attributes train, test\n",
        "2. Make sure digit.train and digit.test are objects of the same type having two \n",
        "attributes features(=array of all the feature vectors) and labels(=array of all the label vectors).\n",
        "Every element of features is a numeric array representing an image \n",
        "(might be an array of greyscale intensity, might be something else).\n",
        "\"\"\"\n",
        "class Dataset():\n",
        "    def __init__(self,train,test):\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "class Data():\n",
        "    def __init__(self,features,labels):\n",
        "        self.features = (features.astype('float32')/ 255.0).reshape(features.shape[0], 28, 28, 1)\n",
        "        new_labels=np.zeros([labels.shape[0],10])\n",
        "        #trainY = to_categorical(trainY)\n",
        "        #testY = to_categorical(testY)\n",
        "        for i,label in enumerate(labels):\n",
        "            new_labels[i,label]=1\n",
        "        self.labels= new_labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzU_S-o4P7Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train=Data(trainX,trainy)\n",
        "test=Data(testX,testy)\n",
        "digits=Dataset(train,test)\n",
        "# to import train features: digits.train.features\n",
        "# to import train features: digits.train.labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL-WP1bNP7Yv",
        "colab_type": "code",
        "outputId": "b1f2290b-9398-4e27-e707-e5f1af7ecd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from keras.models import Sequential\n",
        "#from tf.keras.layers import Flatten,Dense,Activation, Conv2D, MaxPooling2D\n",
        "#from keras.optimizers import SGD\n",
        "# Step - 2: Design the network (To be done by member 2)\n",
        "start = time.time()\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    # compile model\n",
        "    #opt = SGD(lr=0.01, momentum=0.9)\n",
        "  model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #Now train the data on the training Data Set and evlaute on test Data set\n",
        "  learning_history=model.fit(digits.train.features,train.labels,batch_size=200,epochs=100,shuffle=True,validation_split=.1)\n",
        "\n",
        "# Saving the model\n",
        "#model.save('knowledge_CNN.h5')\n",
        "\n",
        "# If one wants to delete the current model in memory\n",
        "#del model\n",
        "end = time.time()\n",
        "print(\"Time taken to learn: {}\". format(end-start))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.8521 - loss: 0.5850 - val_accuracy: 0.9307 - val_loss: 0.2763\n",
            "Epoch 2/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9164 - loss: 0.3031 - val_accuracy: 0.9428 - val_loss: 0.2195\n",
            "Epoch 3/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9294 - loss: 0.2535 - val_accuracy: 0.9503 - val_loss: 0.1902\n",
            "Epoch 4/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9368 - loss: 0.2235 - val_accuracy: 0.9565 - val_loss: 0.1707\n",
            "Epoch 5/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9430 - loss: 0.2012 - val_accuracy: 0.9590 - val_loss: 0.1588\n",
            "Epoch 6/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9476 - loss: 0.1848 - val_accuracy: 0.9635 - val_loss: 0.1441\n",
            "Epoch 7/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9523 - loss: 0.1705 - val_accuracy: 0.9648 - val_loss: 0.1344\n",
            "Epoch 8/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9553 - loss: 0.1587 - val_accuracy: 0.9678 - val_loss: 0.1262\n",
            "Epoch 9/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9585 - loss: 0.1486 - val_accuracy: 0.9678 - val_loss: 0.1183\n",
            "Epoch 10/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9609 - loss: 0.1401 - val_accuracy: 0.9713 - val_loss: 0.1121\n",
            "Epoch 11/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9634 - loss: 0.1322 - val_accuracy: 0.9713 - val_loss: 0.1093\n",
            "Epoch 12/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9651 - loss: 0.1253 - val_accuracy: 0.9720 - val_loss: 0.1061\n",
            "Epoch 13/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9672 - loss: 0.1192 - val_accuracy: 0.9737 - val_loss: 0.1001\n",
            "Epoch 14/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9687 - loss: 0.1137 - val_accuracy: 0.9757 - val_loss: 0.0954\n",
            "Epoch 15/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9704 - loss: 0.1086 - val_accuracy: 0.9767 - val_loss: 0.0944\n",
            "Epoch 16/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9716 - loss: 0.1040 - val_accuracy: 0.9760 - val_loss: 0.0902\n",
            "Epoch 17/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9732 - loss: 0.0994 - val_accuracy: 0.9763 - val_loss: 0.0884\n",
            "Epoch 18/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9742 - loss: 0.0954 - val_accuracy: 0.9772 - val_loss: 0.0878\n",
            "Epoch 19/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9750 - loss: 0.0918 - val_accuracy: 0.9783 - val_loss: 0.0839\n",
            "Epoch 20/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9760 - loss: 0.0886 - val_accuracy: 0.9800 - val_loss: 0.0814\n",
            "Epoch 21/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9770 - loss: 0.0852 - val_accuracy: 0.9797 - val_loss: 0.0805\n",
            "Epoch 22/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9777 - loss: 0.0826 - val_accuracy: 0.9802 - val_loss: 0.0790\n",
            "Epoch 23/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9788 - loss: 0.0797 - val_accuracy: 0.9798 - val_loss: 0.0774\n",
            "Epoch 24/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9795 - loss: 0.0770 - val_accuracy: 0.9803 - val_loss: 0.0759\n",
            "Epoch 25/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9805 - loss: 0.0744 - val_accuracy: 0.9802 - val_loss: 0.0770\n",
            "Epoch 26/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9807 - loss: 0.0724 - val_accuracy: 0.9815 - val_loss: 0.0740\n",
            "Epoch 27/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9814 - loss: 0.0701 - val_accuracy: 0.9813 - val_loss: 0.0733\n",
            "Epoch 28/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9818 - loss: 0.0680 - val_accuracy: 0.9833 - val_loss: 0.0710\n",
            "Epoch 29/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9824 - loss: 0.0663 - val_accuracy: 0.9808 - val_loss: 0.0704\n",
            "Epoch 30/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9830 - loss: 0.0643 - val_accuracy: 0.9823 - val_loss: 0.0687\n",
            "Epoch 31/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9836 - loss: 0.0626 - val_accuracy: 0.9823 - val_loss: 0.0703\n",
            "Epoch 32/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9839 - loss: 0.0609 - val_accuracy: 0.9825 - val_loss: 0.0679\n",
            "Epoch 33/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9842 - loss: 0.0593 - val_accuracy: 0.9825 - val_loss: 0.0672\n",
            "Epoch 34/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9846 - loss: 0.0579 - val_accuracy: 0.9828 - val_loss: 0.0667\n",
            "Epoch 35/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9848 - loss: 0.0565 - val_accuracy: 0.9828 - val_loss: 0.0662\n",
            "Epoch 36/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9856 - loss: 0.0551 - val_accuracy: 0.9833 - val_loss: 0.0643\n",
            "Epoch 37/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9858 - loss: 0.0536 - val_accuracy: 0.9837 - val_loss: 0.0648\n",
            "Epoch 38/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9864 - loss: 0.0524 - val_accuracy: 0.9827 - val_loss: 0.0641\n",
            "Epoch 39/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9862 - loss: 0.0514 - val_accuracy: 0.9842 - val_loss: 0.0632\n",
            "Epoch 40/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9867 - loss: 0.0503 - val_accuracy: 0.9830 - val_loss: 0.0656\n",
            "Epoch 41/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9871 - loss: 0.0488 - val_accuracy: 0.9843 - val_loss: 0.0626\n",
            "Epoch 42/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9873 - loss: 0.0479 - val_accuracy: 0.9833 - val_loss: 0.0624\n",
            "Epoch 43/100\n",
            "270/270 [==============================] - 2s 9ms/step - accuracy: 0.9878 - loss: 0.0469 - val_accuracy: 0.9835 - val_loss: 0.0631\n",
            "Epoch 44/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9881 - loss: 0.0457 - val_accuracy: 0.9847 - val_loss: 0.0613\n",
            "Epoch 45/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9882 - loss: 0.0449 - val_accuracy: 0.9852 - val_loss: 0.0606\n",
            "Epoch 46/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9884 - loss: 0.0438 - val_accuracy: 0.9838 - val_loss: 0.0607\n",
            "Epoch 47/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9886 - loss: 0.0431 - val_accuracy: 0.9843 - val_loss: 0.0591\n",
            "Epoch 48/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9890 - loss: 0.0423 - val_accuracy: 0.9852 - val_loss: 0.0595\n",
            "Epoch 49/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9893 - loss: 0.0414 - val_accuracy: 0.9847 - val_loss: 0.0585\n",
            "Epoch 50/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9896 - loss: 0.0405 - val_accuracy: 0.9848 - val_loss: 0.0600\n",
            "Epoch 51/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9894 - loss: 0.0396 - val_accuracy: 0.9845 - val_loss: 0.0575\n",
            "Epoch 52/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9900 - loss: 0.0390 - val_accuracy: 0.9842 - val_loss: 0.0579\n",
            "Epoch 53/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9901 - loss: 0.0383 - val_accuracy: 0.9847 - val_loss: 0.0569\n",
            "Epoch 54/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9903 - loss: 0.0375 - val_accuracy: 0.9855 - val_loss: 0.0577\n",
            "Epoch 55/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9907 - loss: 0.0368 - val_accuracy: 0.9847 - val_loss: 0.0576\n",
            "Epoch 56/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9907 - loss: 0.0362 - val_accuracy: 0.9847 - val_loss: 0.0564\n",
            "Epoch 57/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9910 - loss: 0.0355 - val_accuracy: 0.9855 - val_loss: 0.0569\n",
            "Epoch 58/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9912 - loss: 0.0347 - val_accuracy: 0.9853 - val_loss: 0.0551\n",
            "Epoch 59/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9912 - loss: 0.0342 - val_accuracy: 0.9850 - val_loss: 0.0565\n",
            "Epoch 60/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9917 - loss: 0.0335 - val_accuracy: 0.9850 - val_loss: 0.0558\n",
            "Epoch 61/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9914 - loss: 0.0331 - val_accuracy: 0.9862 - val_loss: 0.0565\n",
            "Epoch 62/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9920 - loss: 0.0325 - val_accuracy: 0.9855 - val_loss: 0.0559\n",
            "Epoch 63/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9921 - loss: 0.0319 - val_accuracy: 0.9858 - val_loss: 0.0555\n",
            "Epoch 64/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9924 - loss: 0.0314 - val_accuracy: 0.9860 - val_loss: 0.0548\n",
            "Epoch 65/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9923 - loss: 0.0308 - val_accuracy: 0.9845 - val_loss: 0.0566\n",
            "Epoch 66/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9922 - loss: 0.0304 - val_accuracy: 0.9857 - val_loss: 0.0540\n",
            "Epoch 67/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9926 - loss: 0.0298 - val_accuracy: 0.9857 - val_loss: 0.0546\n",
            "Epoch 68/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9931 - loss: 0.0293 - val_accuracy: 0.9855 - val_loss: 0.0560\n",
            "Epoch 69/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9931 - loss: 0.0288 - val_accuracy: 0.9862 - val_loss: 0.0534\n",
            "Epoch 70/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9934 - loss: 0.0285 - val_accuracy: 0.9860 - val_loss: 0.0539\n",
            "Epoch 71/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9935 - loss: 0.0278 - val_accuracy: 0.9855 - val_loss: 0.0544\n",
            "Epoch 72/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9935 - loss: 0.0275 - val_accuracy: 0.9853 - val_loss: 0.0538\n",
            "Epoch 73/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9938 - loss: 0.0270 - val_accuracy: 0.9857 - val_loss: 0.0546\n",
            "Epoch 74/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9936 - loss: 0.0264 - val_accuracy: 0.9855 - val_loss: 0.0537\n",
            "Epoch 75/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9937 - loss: 0.0262 - val_accuracy: 0.9857 - val_loss: 0.0537\n",
            "Epoch 76/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9943 - loss: 0.0257 - val_accuracy: 0.9860 - val_loss: 0.0525\n",
            "Epoch 77/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9943 - loss: 0.0254 - val_accuracy: 0.9855 - val_loss: 0.0534\n",
            "Epoch 78/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9940 - loss: 0.0250 - val_accuracy: 0.9853 - val_loss: 0.0532\n",
            "Epoch 79/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9944 - loss: 0.0247 - val_accuracy: 0.9855 - val_loss: 0.0523\n",
            "Epoch 80/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9945 - loss: 0.0243 - val_accuracy: 0.9850 - val_loss: 0.0534\n",
            "Epoch 81/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9944 - loss: 0.0240 - val_accuracy: 0.9853 - val_loss: 0.0537\n",
            "Epoch 82/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9950 - loss: 0.0235 - val_accuracy: 0.9853 - val_loss: 0.0528\n",
            "Epoch 83/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9945 - loss: 0.0232 - val_accuracy: 0.9855 - val_loss: 0.0523\n",
            "Epoch 84/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9949 - loss: 0.0228 - val_accuracy: 0.9870 - val_loss: 0.0516\n",
            "Epoch 85/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9954 - loss: 0.0225 - val_accuracy: 0.9863 - val_loss: 0.0526\n",
            "Epoch 86/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9951 - loss: 0.0221 - val_accuracy: 0.9870 - val_loss: 0.0509\n",
            "Epoch 87/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9954 - loss: 0.0218 - val_accuracy: 0.9857 - val_loss: 0.0533\n",
            "Epoch 88/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9955 - loss: 0.0214 - val_accuracy: 0.9858 - val_loss: 0.0518\n",
            "Epoch 89/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9956 - loss: 0.0212 - val_accuracy: 0.9860 - val_loss: 0.0507\n",
            "Epoch 90/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9957 - loss: 0.0209 - val_accuracy: 0.9862 - val_loss: 0.0522\n",
            "Epoch 91/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9958 - loss: 0.0205 - val_accuracy: 0.9858 - val_loss: 0.0524\n",
            "Epoch 92/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9960 - loss: 0.0202 - val_accuracy: 0.9860 - val_loss: 0.0515\n",
            "Epoch 93/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9959 - loss: 0.0200 - val_accuracy: 0.9863 - val_loss: 0.0507\n",
            "Epoch 94/100\n",
            "270/270 [==============================] - 2s 9ms/step - accuracy: 0.9960 - loss: 0.0198 - val_accuracy: 0.9865 - val_loss: 0.0519\n",
            "Epoch 95/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9960 - loss: 0.0194 - val_accuracy: 0.9857 - val_loss: 0.0522\n",
            "Epoch 96/100\n",
            "270/270 [==============================] - 3s 11ms/step - accuracy: 0.9962 - loss: 0.0192 - val_accuracy: 0.9870 - val_loss: 0.0509\n",
            "Epoch 97/100\n",
            "270/270 [==============================] - 3s 12ms/step - accuracy: 0.9962 - loss: 0.0190 - val_accuracy: 0.9862 - val_loss: 0.0508\n",
            "Epoch 98/100\n",
            "270/270 [==============================] - 3s 10ms/step - accuracy: 0.9964 - loss: 0.0186 - val_accuracy: 0.9863 - val_loss: 0.0504\n",
            "Epoch 99/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9966 - loss: 0.0183 - val_accuracy: 0.9863 - val_loss: 0.0510\n",
            "Epoch 100/100\n",
            "270/270 [==============================] - 3s 9ms/step - accuracy: 0.9965 - loss: 0.0182 - val_accuracy: 0.9867 - val_loss: 0.0503\n",
            "Time taken to learn: 269.97778701782227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkmYehftP7Y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Saving the model\n",
        "model.save('knowledge_CNN.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZnN4SovP7Y-",
        "colab_type": "code",
        "outputId": "ec3b9ada-bf9c-4b15-f90d-629e9cb9e833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Step - 3: Save/Load and Test our AI (To be done by member 3)\n",
        "# Loading the model\n",
        "#from keras.models import load_model\n",
        "#our_1st_ai=tf.load_model('knowledge_CNN.h5')\n",
        "\n",
        "\"\"\"\n",
        "Last but not the least:\n",
        "1. Save our model as knowledge.h5 file in the same folder as this notebook for future use.\n",
        "2. Load the neural network saved in knowledge.h5 into an object named our_1st_ai.\n",
        "3. Output the accuracy score of our_1st_ai on the training and test samples separately.\n",
        "4. Plot the loss function and model accuracy as a function of epochs using learning_history. \n",
        "\"\"\"\n",
        "\n",
        "score_test,acc_test=model.evaluate(digits.test.features,digits.test.labels,batch_size=100)\n",
        "score_train,acc_train=model.evaluate(digits.train.features,digits.train.labels,batch_size=100)\n",
        "print('Train score:%.4f '%score_train,'Test Score: %.4f '%score_test)\n",
        "print('Train Accuracy: %.2f'%(acc_train*100),'Test Accuracy: %.2f'%(acc_test*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 11ms/step - accuracy: 0.9866 - loss: 0.0433\n",
            "600/600 [==============================] - 6s 10ms/step - accuracy: 0.9961 - loss: 0.0201\n",
            "Train score:0.0201  Test Score: 0.0433 \n",
            "Train Accuracy: 99.61 Test Accuracy: 98.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHJWVV4kP7ZG",
        "colab_type": "code",
        "outputId": "3ceb2763-35ed-4dc3-a3f4-f65bd9d8a878",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,230\n",
            "Trainable params: 542,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOrDUDpOP7ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.axhline(1,linestyle='dashed')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation','loss'], loc='best')\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwaGV1W6P7ZS",
        "colab_type": "code",
        "outputId": "dabcedb7-ace6-490b-b218-305f1b06a28a",
        "colab": {}
      },
      "source": [
        "plt.boxplot(model.history.history['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7f639841d2e8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f639841d630>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f639841d978>,\n",
              "  <matplotlib.lines.Line2D at 0x7f639841dcc0>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7f6398410eb8>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f639841dda0>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f63983aa390>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJfTwq-3P7Zi",
        "colab_type": "code",
        "outputId": "fba99f1a-8742-47c7-f582-24edfe8eee1f",
        "colab": {}
      },
      "source": [
        "# make a prediction for a an image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "    # load the image\n",
        "    img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "    # convert to array\n",
        "    img = img_to_array(img)\n",
        "    # reshape into a single sample with 1 channel\n",
        "    img = img.reshape( 1,28, 28,1)\n",
        "    # prepare pixel data\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "    # load the image\n",
        "    img = load_image('sample_image.png')\n",
        "    # load model\n",
        "    model = load_model('knowledge_CNN.h5')\n",
        "    # predict the class\n",
        "    digit = model.predict_classes(img)\n",
        "    print(digit[0])\n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/srashti/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "copxNbOJP7Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}